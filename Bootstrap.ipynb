{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parametric bootstrap in Julia"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Fabrizzio Sanchez](http://www.stat.wisc.edu/node/2034) suggested that bootstrapping a statistical model as a non-trivial task on which to demonstrate the speed of [Julia](http://www.stat.wisc.edu).\n",
      "\n",
      "In this notebook I will demonstrate a _parametric bootstrap_, wherein the fitted values of the model parameters are fixed at their estimated values and samples are generated and fit according to the probability model.\n",
      "\n",
      "A simple example is a _linear model_ which can be fit using the `GLM` package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using GLM, RDatasets\n",
      "ls = dataset(\"datasets\",\"LifeCycleSavings\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"data-frame\"><tr><th></th><th>Country</th><th>SR</th><th>Pop15</th><th>Pop75</th><th>DPI</th><th>DDPI</th></tr><tr><th>1</th><td>Australia</td><td>11.43</td><td>29.35</td><td>2.87</td><td>2329.68</td><td>2.87</td></tr><tr><th>2</th><td>Austria</td><td>12.07</td><td>23.32</td><td>4.41</td><td>1507.99</td><td>3.93</td></tr><tr><th>3</th><td>Belgium</td><td>13.17</td><td>23.8</td><td>4.43</td><td>2108.47</td><td>3.82</td></tr><tr><th>4</th><td>Bolivia</td><td>5.75</td><td>41.89</td><td>1.67</td><td>189.13</td><td>0.22</td></tr><tr><th>5</th><td>Brazil</td><td>12.88</td><td>42.19</td><td>0.83</td><td>728.47</td><td>4.56</td></tr><tr><th>6</th><td>Canada</td><td>8.79</td><td>31.72</td><td>2.85</td><td>2982.88</td><td>2.43</td></tr><tr><th>7</th><td>Chile</td><td>0.6</td><td>39.74</td><td>1.34</td><td>662.86</td><td>2.67</td></tr><tr><th>8</th><td>China</td><td>11.9</td><td>44.75</td><td>0.67</td><td>289.52</td><td>6.51</td></tr><tr><th>9</th><td>Colombia</td><td>4.98</td><td>46.64</td><td>1.06</td><td>276.65</td><td>3.08</td></tr><tr><th>10</th><td>Costa Rica</td><td>10.78</td><td>47.64</td><td>1.14</td><td>471.24</td><td>2.8</td></tr><tr><th>11</th><td>Denmark</td><td>16.85</td><td>24.42</td><td>3.93</td><td>2496.53</td><td>3.99</td></tr><tr><th>12</th><td>Ecuador</td><td>3.59</td><td>46.31</td><td>1.19</td><td>287.77</td><td>2.19</td></tr><tr><th>13</th><td>Finland</td><td>11.24</td><td>27.84</td><td>2.37</td><td>1681.25</td><td>4.32</td></tr><tr><th>14</th><td>France</td><td>12.64</td><td>25.06</td><td>4.7</td><td>2213.82</td><td>4.52</td></tr><tr><th>15</th><td>Germany</td><td>12.55</td><td>23.31</td><td>3.35</td><td>2457.12</td><td>3.44</td></tr><tr><th>16</th><td>Greece</td><td>10.67</td><td>25.62</td><td>3.1</td><td>870.85</td><td>6.28</td></tr><tr><th>17</th><td>Guatamala</td><td>3.01</td><td>46.05</td><td>0.87</td><td>289.71</td><td>1.48</td></tr><tr><th>18</th><td>Honduras</td><td>7.7</td><td>47.32</td><td>0.58</td><td>232.44</td><td>3.19</td></tr><tr><th>19</th><td>Iceland</td><td>1.27</td><td>34.03</td><td>3.08</td><td>1900.1</td><td>1.12</td></tr><tr><th>20</th><td>India</td><td>9.0</td><td>41.31</td><td>0.96</td><td>88.94</td><td>1.54</td></tr><tr><th>21</th><td>Ireland</td><td>11.34</td><td>31.16</td><td>4.19</td><td>1139.95</td><td>2.99</td></tr><tr><th>22</th><td>Italy</td><td>14.28</td><td>24.52</td><td>3.48</td><td>1390.0</td><td>3.54</td></tr><tr><th>23</th><td>Japan</td><td>21.1</td><td>27.01</td><td>1.91</td><td>1257.28</td><td>8.21</td></tr><tr><th>24</th><td>Korea</td><td>3.98</td><td>41.74</td><td>0.91</td><td>207.68</td><td>5.81</td></tr><tr><th>25</th><td>Luxembourg</td><td>10.35</td><td>21.8</td><td>3.73</td><td>2449.39</td><td>1.57</td></tr><tr><th>26</th><td>Malta</td><td>15.48</td><td>32.54</td><td>2.47</td><td>601.05</td><td>8.12</td></tr><tr><th>27</th><td>Norway</td><td>10.25</td><td>25.95</td><td>3.67</td><td>2231.03</td><td>3.62</td></tr><tr><th>28</th><td>Netherlands</td><td>14.65</td><td>24.71</td><td>3.25</td><td>1740.7</td><td>7.66</td></tr><tr><th>29</th><td>New Zealand</td><td>10.67</td><td>32.61</td><td>3.17</td><td>1487.52</td><td>1.76</td></tr><tr><th>30</th><td>Nicaragua</td><td>7.3</td><td>45.04</td><td>1.21</td><td>325.54</td><td>2.48</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "50x6 DataFrame\n",
        "|-------|------------------|-------|-------|-------|---------|-------|\n",
        "| Row # | Country          | SR    | Pop15 | Pop75 | DPI     | DDPI  |\n",
        "| 1     | \"Australia\"      | 11.43 | 29.35 | 2.87  | 2329.68 | 2.87  |\n",
        "| 2     | \"Austria\"        | 12.07 | 23.32 | 4.41  | 1507.99 | 3.93  |\n",
        "| 3     | \"Belgium\"        | 13.17 | 23.8  | 4.43  | 2108.47 | 3.82  |\n",
        "| 4     | \"Bolivia\"        | 5.75  | 41.89 | 1.67  | 189.13  | 0.22  |\n",
        "| 5     | \"Brazil\"         | 12.88 | 42.19 | 0.83  | 728.47  | 4.56  |\n",
        "| 6     | \"Canada\"         | 8.79  | 31.72 | 2.85  | 2982.88 | 2.43  |\n",
        "| 7     | \"Chile\"          | 0.6   | 39.74 | 1.34  | 662.86  | 2.67  |\n",
        "| 8     | \"China\"          | 11.9  | 44.75 | 0.67  | 289.52  | 6.51  |\n",
        "| 9     | \"Colombia\"       | 4.98  | 46.64 | 1.06  | 276.65  | 3.08  |\n",
        "| 10    | \"Costa Rica\"     | 10.78 | 47.64 | 1.14  | 471.24  | 2.8   |\n",
        "| 11    | \"Denmark\"        | 16.85 | 24.42 | 3.93  | 2496.53 | 3.99  |\n",
        "\u22ee\n",
        "| 39    | \"Sweden\"         | 6.86  | 21.44 | 4.54  | 3299.49 | 3.01  |\n",
        "| 40    | \"Switzerland\"    | 14.13 | 23.49 | 3.73  | 2630.96 | 2.7   |\n",
        "| 41    | \"Turkey\"         | 5.13  | 43.42 | 1.08  | 389.66  | 2.96  |\n",
        "| 42    | \"Tunisia\"        | 2.81  | 46.12 | 1.21  | 249.87  | 1.13  |\n",
        "| 43    | \"United Kingdom\" | 7.81  | 23.27 | 4.46  | 1813.93 | 2.01  |\n",
        "| 44    | \"United States\"  | 7.56  | 29.81 | 3.43  | 4001.89 | 2.45  |\n",
        "| 45    | \"Venezuela\"      | 9.22  | 46.4  | 0.9   | 813.39  | 0.53  |\n",
        "| 46    | \"Zambia\"         | 18.56 | 45.25 | 0.56  | 138.33  | 5.14  |\n",
        "| 47    | \"Jamaica\"        | 7.72  | 41.12 | 1.73  | 380.47  | 10.23 |\n",
        "| 48    | \"Uruguay\"        | 9.24  | 28.13 | 2.72  | 766.54  | 1.88  |\n",
        "| 49    | \"Libya\"          | 8.89  | 43.69 | 2.07  | 123.58  | 16.71 |\n",
        "| 50    | \"Malaysia\"       | 4.71  | 47.2  | 0.66  | 242.69  | 5.08  |"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1 = lm(SR ~ Pop15 + Pop75 + DPI + DDPI, ls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "DataFrameRegressionModel{LinearModel{DensePredQR{Float64}},Float64}:\n",
        "\n",
        "Coefficients:\n",
        "                 Estimate   Std.Error   t value Pr(>|t|)\n",
        "(Intercept)       28.5661     7.35452   3.88416   0.0003\n",
        "Pop15           -0.461193    0.144642  -3.18851   0.0026\n",
        "Pop75             -1.6915      1.0836    -1.561   0.1255\n",
        "DPI          -0.000336902 0.000931107 -0.361829   0.7192\n",
        "DDPI             0.409695    0.196197   2.08818   0.0425\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will take the fitted values and the estimate of the scale parameter from this model as the mean and scale parameter of a multivariate normal distribution from which to simulate new response vectors.\n",
      "\n",
      "Getting the fitted values turned out to be more complicated than I thought it would be because I hadn't written the appropriate method.  For now we will use the somewhat mysterious extractor `m1.model.rr.mu` to get this.\n",
      "\n",
      "We will use the `IsoNormal` type of multivariate normal distribution from the `Distributions` package for simulating the responses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = IsoNormal(m1.model.rr.mu,scale(m1.model))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "GenericMvNormal{ScalMat} distribution\n",
        "Dim: 50\n",
        "Zeromean: false\n",
        "\u039c:\n",
        "[10.5664,11.4536,10.951,6.44832,9.32719,9.10689,8.84223,9.36396,6.43171,5.65492  \u2026  7.79568,5.62792,10.5024,8.67159,5.58748,8.80909,10.7385,11.5038,11.7195,7.68087]\n",
        "\u03a3: ScalMat(50,14.460288848169613,0.06915491180707502)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting the coefficients."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A simple method of obtaining the coefficients from fitting the model matrix to a new simulated response is the `lm` method for a model matrix and a response."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = copy(m1.model.pp.X) # copy the X matrix from the predictor field, pp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "50x5 Array{Float64,2}:\n",
        " 1.0  29.35  2.87  2329.68   2.87\n",
        " 1.0  23.32  4.41  1507.99   3.93\n",
        " 1.0  23.8   4.43  2108.47   3.82\n",
        " 1.0  41.89  1.67   189.13   0.22\n",
        " 1.0  42.19  0.83   728.47   4.56\n",
        " 1.0  31.72  2.85  2982.88   2.43\n",
        " 1.0  39.74  1.34   662.86   2.67\n",
        " 1.0  44.75  0.67   289.52   6.51\n",
        " 1.0  46.64  1.06   276.65   3.08\n",
        " 1.0  47.64  1.14   471.24   2.8 \n",
        " 1.0  24.42  3.93  2496.53   3.99\n",
        " 1.0  46.31  1.19   287.77   2.19\n",
        " 1.0  27.84  2.37  1681.25   4.32\n",
        " \u22ee                               \n",
        " 1.0  21.44  4.54  3299.49   3.01\n",
        " 1.0  23.49  3.73  2630.96   2.7 \n",
        " 1.0  43.42  1.08   389.66   2.96\n",
        " 1.0  46.12  1.21   249.87   1.13\n",
        " 1.0  23.27  4.46  1813.93   2.01\n",
        " 1.0  29.81  3.43  4001.89   2.45\n",
        " 1.0  46.4   0.9    813.39   0.53\n",
        " 1.0  45.25  0.56   138.33   5.14\n",
        " 1.0  41.12  1.73   380.47  10.23\n",
        " 1.0  28.13  2.72   766.54   1.88\n",
        " 1.0  43.69  2.07   123.58  16.71\n",
        " 1.0  47.2   0.66   242.69   5.08"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm(X,rand(d))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "LinearModel{DensePredQR{Float64}}:\n",
        "\n",
        "Coefficients:         Estimate  Std.Error   t value Pr(>|t|)\n",
        "x1        25.4981    8.25604   3.08842   0.0034\n",
        "x2      -0.405452   0.162373  -2.49705   0.0162\n",
        "x3        -0.9891    1.21643 -0.813119   0.4204\n",
        "x4   -0.000705928 0.00104524 -0.675373   0.5029\n",
        "x5       0.182683   0.220247  0.829446   0.4112\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose that we want the coefficient estimates, $\\widehat{\\beta}$, and the scale parameter estimate, $\\widehat{\\sigma}$, from, say, 10000 simulated responses for this model.\n",
      "\n",
      "For a single fit we can extract both of these and concatenate them as a vector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sm1 = lm(X,rand(d))\n",
      "[coef(sm1), scale(sm1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "6-element Array{Float64,1}:\n",
        " 12.2265    \n",
        " -0.144429  \n",
        "  1.09908   \n",
        " -0.00113248\n",
        "  0.443073  \n",
        "  4.05752   "
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's express this as a function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samp1(X::Matrix,d) = (sm = lm(X,rand(d)); [coef(sm), scale(sm)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "samp1 (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samp1(X,d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "6-element Array{Float64,1}:\n",
        " 33.5739    \n",
        " -0.547009  \n",
        " -3.25327   \n",
        "  0.00100107\n",
        "  0.553582  \n",
        "  4.03469   "
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creating the parametric bootstrap sample"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest way to create a parametric bootstrap sample of these parameter estimates is as a comprehension."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bss = [samp1(X,d) for i in 1:10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "10000-element Array{Any,1}:\n",
        " [20.3207,-0.342121,-1.32464,0.00111186,0.810764,3.32482]  \n",
        " [24.1062,-0.344598,-1.37886,0.000576011,0.283401,3.77328] \n",
        " [35.635,-0.575939,-4.06721,0.000832344,0.676826,4.03701]  \n",
        " [28.6388,-0.502386,-1.68238,-0.000125758,0.639186,3.84276]\n",
        " [32.947,-0.57578,-2.49766,-0.000352524,0.650275,3.85546]  \n",
        " [31.8404,-0.526047,-0.959473,-0.00278757,0.496021,3.79154]\n",
        " [37.1722,-0.591517,-2.923,4.27237e-5,0.0788234,3.42352]   \n",
        " [13.506,-0.180572,0.357042,0.000154463,0.435685,3.47374]  \n",
        " [24.0606,-0.348861,-2.21371,0.000940063,0.534003,4.00972] \n",
        " [23.9594,-0.371708,-0.0449226,-0.00180537,0.273371,3.9333]\n",
        " [25.304,-0.396134,-1.33583,0.000155199,0.194428,3.60708]  \n",
        " [19.4879,-0.264566,-1.09231,7.18145e-5,0.419144,4.04023]  \n",
        " [16.5114,-0.247138,0.122456,-0.000239269,0.522304,3.64409]\n",
        " \u22ee                                                         \n",
        " [34.6996,-0.604249,-4.15038,0.00171964,0.941451,4.09364]  \n",
        " [28.9764,-0.4421,-1.83933,4.97715e-5,0.214954,4.3627]     \n",
        " [27.7749,-0.455885,-1.73315,0.00031832,0.47416,3.7219]    \n",
        " [21.1238,-0.291539,0.308817,-0.00235315,0.391791,4.05653] \n",
        " [37.5815,-0.685426,-1.39783,-0.0021523,0.415453,4.00434]  \n",
        " [29.458,-0.496323,-2.05692,0.000311295,0.706154,3.67618]  \n",
        " [33.2476,-0.598001,-2.02155,-0.000518833,0.562419,3.65442]\n",
        " [31.556,-0.487835,-2.30219,0.000435587,0.200776,3.75686]  \n",
        " [16.0846,-0.244155,-0.101269,-9.55661e-5,0.492124,3.55577]\n",
        " [25.2927,-0.419518,-2.33786,0.00227246,0.479972,3.53956]  \n",
        " [28.1561,-0.470716,-1.60317,-0.000109652,0.373037,3.43573]\n",
        " [39.4679,-0.668917,-3.26202,-0.000593988,0.554276,4.13984]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time [samp1(X,d) for i in 1:10000];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".11761955 seconds (329511888 bytes allocated, 17.02% gc time)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we see, this produces the sample in the form of an array of vectors, as opposed to, say, a matrix, is not blazingly fast, allocates a lot of memory and spends about 1/6 of the time in garbage collection.\n",
      "\n",
      "What is happening here is that all the work of creating the model object and factoring the model matrix is (unnecessarily) being done for every sample."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preallocating the result"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A common idiom in Julia is to create a mutating version of a function that overwrites an argument and a non-mutating version that allocates the object to be overwritten and calls the mutating version.\n",
      "\n",
      "We first create the mutating `bootstrap!` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function bootstrap!(samp::Matrix, m::LinearModel, f::Function)\n",
      "    length(f(m)) == size(samp,1) || throw(DimensionMismatch(\"\"))\n",
      "    \u03bc = m.rr.mu\n",
      "    \u03c3 = scale(m)\n",
      "    d = IsoNormal(\u03bc, \u03c3)\n",
      "    X = m.pp.X\n",
      "    for j in 1:size(samp,2)\n",
      "        samp[:,j] = f(fit(LinearModel,X,rand(d)))\n",
      "    end\n",
      "    samp\n",
      "end\n",
      "function bootstrap(nsamp::Integer, m::LinearModel, f::Function)\n",
      "    fm = f(m)\n",
      "    bootstrap!(similar(fm,(length(fm),nsamp)), m, f)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "bootstrap (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f(m::LinearModel) = [coef(m), scale(m)]\n",
      "samp = bootstrap(10000,m1.model,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "6x10000 Array{Float64,2}:\n",
        " 30.6452      29.1265       27.3354       \u2026  37.4967       24.2506     \n",
        " -0.468522    -0.439509     -0.428579        -0.639624     -0.382411   \n",
        " -1.19654     -1.60665      -1.81538         -2.3344       -1.05744    \n",
        " -0.00114633  -0.000299992   0.000280983     -0.000874603  -0.000508149\n",
        "  0.107378     0.0625784     0.240423         0.281497      0.426859   \n",
        "  3.57028      4.64197       3.58069      \u2026   4.30057       4.43112    "
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time bootstrap(10000,m1.model,f);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".119894181 seconds (330158632 bytes allocated, 16.90% gc time)\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time bootstrap!(samp,m1.model,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".09900701 seconds (329673840 bytes allocated, 17.05% gc time)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "6x10000 Array{Float64,2}:\n",
        " 29.8776       41.9235       27.7905      \u2026  34.728       37.797      \n",
        " -0.48996      -0.731295     -0.445717       -0.597839    -0.672437   \n",
        " -1.8653       -3.64595      -0.891633       -1.29571     -2.1447     \n",
        " -0.000380517  -0.000443381  -0.00225305     -0.00156384  -0.000744399\n",
        "  0.383354      0.65137       0.376429       -0.0269874    0.197796   \n",
        "  3.87741       3.62115       4.24648     \u2026   4.00238      4.37629    "
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we are still not doing very well.  The problem is that I got carried away in designing the LinearModel types and it is difficult to get the desired quantities without creating the factorization all over again."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using the matrix factorization directly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The best way of speeding this process up is to code the calculations directly, taking advantage of the fact that the fitted model contains a factorization of the model matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "typeof(m1.model.pp.qr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "QRCompactWY{Float64} (constructor with 1 method)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and we can get the coefficient estimates as"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1.model.pp.qr\\rand(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "5-element Array{Float64,1}:\n",
        " 40.9246    \n",
        " -0.70034   \n",
        " -3.42037   \n",
        "  6.63232e-5\n",
        "  0.535858  "
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get the residual sum of squares we use the `sumsqdiff` function from the `NumericExtensions` package.  It accumulates the residual sum of squares without storing the residuals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using NumericExtensions\n",
      "y = m1.model.rr.y\n",
      "\u03bc = m1.model.rr.mu\n",
      "rss = sumsqdiff(y,\u03bc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "650.7129981676326"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@time sumsqdiff(y,\u03bc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".933e-6 seconds (144 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "650.7129981676326"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function bootlmcoefscale!(res::Matrix,X::Matrix,y::Vector)\n",
      "    n,p = size(X)\n",
      "    length(y) == n || throw(DimensionMismatch(\"\"))\n",
      "    size(res,1) == p + 1 || throw(DimensionMismatch(\"\"))\n",
      "    fac = qrfact(X)\n",
      "    \u03b2 = fac\\y\n",
      "    \u03bc = X*\u03b2\n",
      "    df = float(size(X,1) - size(X,2))\n",
      "    d = IsoNormal(\u03bc,sqrt(sumsqdiff(y,\u03bc)/df))\n",
      "    for j in 1:size(res,2)\n",
      "        copy!(\u03b2,Base.A_ldiv_B!(fac,copy!(\u03bc,rand!(d,y))))\n",
      "        for i in 1:p\n",
      "            res[i,j] = \u03b2[i]\n",
      "        end\n",
      "        res[end,j] = sqrt(sumsqdiff(y,Base.A_mul_B!(\u03bc,X,\u03b2)))\n",
      "    end\n",
      "    res\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "bootlmcoefscale! (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = Array(Float64,(6,10000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "6x10000 Array{Float64,2}:\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
        " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bootlmcoefscale!(res,m1.model.pp.X,copy(m1.model.rr.y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "6x10000 Array{Float64,2}:\n",
        " 29.992       29.9637       18.1333       \u2026  -360.786     -348.701   \n",
        " -0.4622      -0.502117     -0.283379           7.64471      7.44777 \n",
        " -3.1672      -3.23167      -0.728579         141.333      139.058   \n",
        "  0.00146265   0.000688739  -0.000202728       -0.152303    -0.152723\n",
        "  0.339923     0.925727      0.712189         -12.6623     -12.3875  \n",
        " 25.3484      28.3615       24.9301       \u2026    24.3967      25.2139  "
       ]
      }
     ],
     "prompt_number": 57
    }
   ],
   "metadata": {}
  }
 ]
}